#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
–ú–æ–¥—É–ª—å –¥–ª—è –æ–±—É—á–µ–Ω–∏—è —Å–∏—Å—Ç–µ–º—ã –Ω–∞ —Å—É—â–µ—Å—Ç–≤—É—é—â–∏—Ö –¥–∞–Ω–Ω—ã—Ö
–ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ—Ç product1.xlsx –∏ sku_vkus.xlsx –¥–ª—è –ø–æ—Å—Ç—Ä–æ–µ–Ω–∏—è –±–∞–∑—ã –∑–Ω–∞–Ω–∏–π
"""

import pandas as pd
import json
from typing import Dict, List, Tuple
from collections import Counter, defaultdict
import re
from product_parser import ProductNameParser, ProductFeatures
from brand_matcher import BrandMatcher, FlavorMatcher
from rapidfuzz import fuzz


class LearningEngine:
    """–î–≤–∏–∂–æ–∫ –º–∞—à–∏–Ω–Ω–æ–≥–æ –æ–±—É—á–µ–Ω–∏—è –Ω–∞ –∏—Å—Ç–æ—Ä–∏—á–µ—Å–∫–∏—Ö –¥–∞–Ω–Ω—ã—Ö"""
    
    def __init__(self, product_file: str, sku_file: str, 
                 knowledge_base_path: str = 'knowledge_base.json',
                 brands_db_path: str = 'brands_db.json'):
        self.product_file = product_file
        self.sku_file = sku_file
        self.knowledge_base_path = knowledge_base_path
        self.brands_db_path = brands_db_path
        
        # –ö–æ–º–ø–æ–Ω–µ–Ω—Ç—ã —Å–∏—Å—Ç–µ–º—ã
        self.parser = ProductNameParser(knowledge_base_path)
        self.brand_matcher = BrandMatcher(brands_db_path)
        self.flavor_matcher = FlavorMatcher()
        
        # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –æ–±—É—á–µ–Ω–∏—è
        self.stats = {
            'total_products': 0,
            'brands_learned': 0,
            'flavors_learned': 0,
            'patterns_learned': 0,
            'categories_learned': 0
        }
        
        # –ë–∞–∑—ã –∑–Ω–∞–Ω–∏–π
        self.knowledge_base = {
            'brands': {},
            'flavors': {},
            'categories': {},
            'volume_categories': {},
            'packaging_types': {},
            'brand_patterns': {},
            'flavor_patterns': {},
            'product_types': {}
        }
    
    def load_data(self) -> Tuple[pd.DataFrame, pd.DataFrame]:
        """–ó–∞–≥—Ä—É–∑–∫–∞ –¥–∞–Ω–Ω—ã—Ö –∏–∑ Excel —Ñ–∞–π–ª–æ–≤"""
        print("–ó–∞–≥—Ä—É–∑–∫–∞ –¥–∞–Ω–Ω—ã—Ö...")
        product_df = pd.read_excel(self.product_file)
        sku_df = pd.read_excel(self.sku_file)
        
        print(f"–ó–∞–≥—Ä—É–∂–µ–Ω–æ –ø—Ä–æ–¥—É–∫—Ç–æ–≤: {len(product_df)}")
        print(f"–ó–∞–≥—Ä—É–∂–µ–Ω–æ SKU: {len(sku_df)}")
        
        return product_df, sku_df
    
    def learn_from_data(self):
        """–û—Å–Ω–æ–≤–Ω–æ–π –º–µ—Ç–æ–¥ –æ–±—É—á–µ–Ω–∏—è –Ω–∞ –¥–∞–Ω–Ω—ã—Ö"""
        print("\n" + "="*80)
        print("–ù–ê–ß–ê–õ–û –û–ë–£–ß–ï–ù–ò–Ø –°–ò–°–¢–ï–ú–´")
        print("="*80 + "\n")
        
        product_df, sku_df = self.load_data()
        
        self.stats['total_products'] = len(product_df)
        
        # 1. –û–±—É—á–µ–Ω–∏–µ –Ω–∞ –±—Ä–µ–Ω–¥–∞—Ö
        print("–≠—Ç–∞–ø 1: –û–±—É—á–µ–Ω–∏–µ —Ä–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏—é –±—Ä–µ–Ω–¥–æ–≤...")
        self._learn_brands(product_df)
        
        # 2. –û–±—É—á–µ–Ω–∏–µ –Ω–∞ –≤–∫—É—Å–∞—Ö
        print("\n–≠—Ç–∞–ø 2: –û–±—É—á–µ–Ω–∏–µ —Ä–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏—é –≤–∫—É—Å–æ–≤...")
        self._learn_flavors(sku_df)
        
        # 3. –û–±—É—á–µ–Ω–∏–µ –Ω–∞ –∫–∞—Ç–µ–≥–æ—Ä–∏—è—Ö
        print("\n–≠—Ç–∞–ø 3: –û–±—É—á–µ–Ω–∏–µ –∫–∞—Ç–µ–≥–æ—Ä–∏—è–º —Ç–æ–≤–∞—Ä–æ–≤...")
        self._learn_categories(product_df)
        
        # 4. –û–±—É—á–µ–Ω–∏–µ –Ω–∞ –æ–±—ä–µ–º–∞—Ö
        print("\n–≠—Ç–∞–ø 4: –û–±—É—á–µ–Ω–∏–µ –∫–∞—Ç–µ–≥–æ—Ä–∏—è–º –æ–±—ä–µ–º–æ–≤...")
        self._learn_volumes(product_df)
        
        # 5. –ê–Ω–∞–ª–∏–∑ –ø–∞—Ç—Ç–µ—Ä–Ω–æ–≤ –≤ –Ω–∞–∑–≤–∞–Ω–∏—è—Ö
        print("\n–≠—Ç–∞–ø 5: –ê–Ω–∞–ª–∏–∑ –ø–∞—Ç—Ç–µ—Ä–Ω–æ–≤ –≤ –Ω–∞–∑–≤–∞–Ω–∏—è—Ö...")
        self._learn_patterns(product_df, sku_df)
        
        # 6. –û–±—É—á–µ–Ω–∏–µ –Ω–∞ —Ç–∏–ø–∞—Ö —É–ø–∞–∫–æ–≤–∫–∏
        print("\n–≠—Ç–∞–ø 6: –û–±—É—á–µ–Ω–∏–µ —Ç–∏–ø–∞–º —É–ø–∞–∫–æ–≤–∫–∏...")
        self._learn_packaging(product_df)
        
        # 7. –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –±–∞–∑—ã –∑–Ω–∞–Ω–∏–π
        print("\n–°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –±–∞–∑—ã –∑–Ω–∞–Ω–∏–π...")
        self._save_knowledge_base()
        
        # –í—ã–≤–æ–¥ —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏
        self._print_statistics()
        
        return self.knowledge_base
    
    def _learn_brands(self, df: pd.DataFrame):
        """–û–±—É—á–µ–Ω–∏–µ –Ω–∞ –±—Ä–µ–Ω–¥–∞—Ö"""
        brand_examples = defaultdict(list)
        brand_variations = defaultdict(set)
        
        print("  –ê–Ω–∞–ª–∏–∑ –±—Ä–µ–Ω–¥–æ–≤ –∏–∑ –¥–∞–Ω–Ω—ã—Ö...")
        processed = 0
        
        for _, row in df.iterrows():
            xname = str(row.get('xname', '')).upper()
            brand = str(row.get('brand', '')).strip()
            
            if brand and brand != 'LOCAL' and brand != 'nan':
                brand_upper = brand.upper()
                brand_examples[brand_upper].append(xname)
                
                # –ò–∑–≤–ª–µ–∫–∞–µ–º –≤–∞—Ä–∏–∞—Ü–∏–∏ –Ω–∞–ø–∏—Å–∞–Ω–∏—è –±—Ä–µ–Ω–¥–∞ –∏–∑ xname
                # –ò—â–µ–º –±—Ä–µ–Ω–¥ –≤ —Ä–∞–∑–Ω—ã—Ö —Ñ–æ—Ä–º–∞—Ö
                if brand_upper in xname:
                    # –ò–∑–≤–ª–µ–∫–∞–µ–º —Å–ª–æ–≤–∞ –≤–æ–∫—Ä—É–≥ –±—Ä–µ–Ω–¥–∞
                    words = re.findall(r'\b[–ê-–ØA-Z][–ê-–ØA-Z0-9\-]*\b', xname)
                    for word in words:
                        # –ï—Å–ª–∏ —Å–ª–æ–≤–æ –ø–æ—Ö–æ–∂–µ –Ω–∞ –±—Ä–µ–Ω–¥ (fuzzy matching)
                        if len(word) >= 3:
                            ratio = fuzz.ratio(word, brand_upper)
                            if ratio >= 75:  # –ü–æ—Ö–æ–∂–µ –Ω–∞ –±—Ä–µ–Ω–¥
                                brand_variations[brand_upper].add(word)
                
                # –î–æ–±–∞–≤–ª—è–µ–º –±—Ä–µ–Ω–¥ –≤ –±–∞–∑—É
                self.brand_matcher.add_brand_to_db(brand_upper)
                
                # –£—á–∏–º —Å–∏—Å—Ç–µ–º—É –Ω–∞ –ø—Ä–∏–º–µ—Ä–µ
                self.brand_matcher.learn_brand_variation(xname, brand_upper)
                
                processed += 1
                if processed % 1000 == 0:
                    print(f"    –û–±—Ä–∞–±–æ—Ç–∞–Ω–æ: {processed}/{len(df)}")
        
        # –î–æ–±–∞–≤–ª—è–µ–º –≤–∞—Ä–∏–∞—Ü–∏–∏ –≤ –±–∞–∑—É –±—Ä–µ–Ω–¥–æ–≤
        for brand, variations in brand_variations.items():
            for variation in variations:
                if variation != brand:  # –ù–µ –¥–æ–±–∞–≤–ª—è–µ–º —Å–∞–º –±—Ä–µ–Ω–¥ –∫–∞–∫ –≤–∞—Ä–∏–∞—Ü–∏—é
                    self.brand_matcher.learn_brand_variation(variation, brand)
        
        self.stats['brands_learned'] = len(brand_examples)
        
        # –°–æ—Ö—Ä–∞–Ω—è–µ–º –ø—Ä–∏–º–µ—Ä—ã –≤ –±–∞–∑—É –∑–Ω–∞–Ω–∏–π
        self.knowledge_base['brands'] = {
            brand: {
                'count': len(examples),
                'examples': examples[:10],
                'variations': list(brand_variations.get(brand, []))[:20]
            }
            for brand, examples in brand_examples.items()
        }
        
        print(f"\n  ‚úì –ò–∑—É—á–µ–Ω–æ –±—Ä–µ–Ω–¥–æ–≤: {self.stats['brands_learned']}")
        print(f"  ‚úì –û–±—Ä–∞–±–æ—Ç–∞–Ω–æ —Ç–æ–≤–∞—Ä–æ–≤: {processed}")
        print(f"\n  üìä –¢–æ–ø-20 –±—Ä–µ–Ω–¥–æ–≤ –ø–æ –ø–æ–ø—É–ª—è—Ä–Ω–æ—Å—Ç–∏:")
        top_brands = sorted(brand_examples.items(), key=lambda x: len(x[1]), reverse=True)[:20]
        for i, (brand, examples) in enumerate(top_brands, 1):
            variations = brand_variations.get(brand, set())
            var_str = f" ({len(variations)} –≤–∞—Ä–∏–∞—Ü–∏–π)" if variations else ""
            print(f"    {i:2d}. {brand:30s} - {len(examples):5d} —Ç–æ–≤–∞—Ä–æ–≤{var_str}")
    
    def _learn_flavors(self, df: pd.DataFrame):
        """–û–±—É—á–µ–Ω–∏–µ –Ω–∞ –≤–∫—É—Å–∞—Ö"""
        flavor_examples = defaultdict(list)
        flavor_aliases = defaultdict(set)
        
        for _, row in df.iterrows():
            xname = str(row.get('xname', '')).upper()
            vkus = str(row.get('vkus', '')).strip()
            
            if vkus and vkus not in ['LOCAL', 'CLASSIC', 'nan']:
                vkus_upper = vkus.upper()
                flavor_examples[vkus_upper].append(xname)
                
                # –î–æ–±–∞–≤–ª—è–µ–º –≤–∫—É—Å –≤ FlavorMatcher
                self.flavor_matcher.add_flavor(vkus_upper)
                
                # –ü—ã—Ç–∞–µ–º—Å—è –∏–∑–≤–ª–µ—á—å –∞–ª–∏–∞—Å—ã –∏–∑ –Ω–∞–∑–≤–∞–Ω–∏—è
                # –ù–∞–ø—Ä–∏–º–µ—Ä, –∏–∑ "–Ø–ë–õ–û–ö–û" –º–æ–∂–µ–º –Ω–∞–π—Ç–∏ "APPLE", "–Ø–ë–õ–û–ß–ù–´–ô"
                words = re.findall(r'\b[–ê-–ØA-Z]{3,}\b', xname)
                for word in words:
                    if fuzz.ratio(word, vkus_upper) >= 70:
                        flavor_aliases[vkus_upper].add(word)
        
        # –°–æ—Ö—Ä–∞–Ω—è–µ–º –∞–ª–∏–∞—Å—ã –≤ FlavorMatcher
        for flavor, aliases in flavor_aliases.items():
            self.flavor_matcher.add_flavor(flavor, list(aliases))
        
        # –°–æ—Ö—Ä–∞–Ω—è–µ–º –±–∞–∑—É –≤–∫—É—Å–æ–≤
        self.flavor_matcher.save_flavors_db()
        
        self.stats['flavors_learned'] = len(flavor_examples)
        
        # –°–æ—Ö—Ä–∞–Ω—è–µ–º –≤ –±–∞–∑—É –∑–Ω–∞–Ω–∏–π
        self.knowledge_base['flavors'] = {
            flavor: {
                'count': len(examples),
                'examples': examples[:10],
                'aliases': list(flavor_aliases.get(flavor, []))
            }
            for flavor, examples in flavor_examples.items()
        }
        
        print(f"  –ò–∑—É—á–µ–Ω–æ –≤–∫—É—Å–æ–≤: {self.stats['flavors_learned']}")
        print(f"  –¢–æ–ø-20 –≤–∫—É—Å–æ–≤:")
        top_flavors = sorted(flavor_examples.items(), key=lambda x: len(x[1]), reverse=True)[:20]
        for flavor, examples in top_flavors:
            aliases = flavor_aliases.get(flavor, set())
            aliases_str = f" (–∞–ª–∏–∞—Å—ã: {', '.join(list(aliases)[:3])})" if aliases else ""
            print(f"    {flavor}: {len(examples)} —Ç–æ–≤–∞—Ä–æ–≤{aliases_str}")
    
    def _learn_categories(self, df: pd.DataFrame):
        """–û–±—É—á–µ–Ω–∏–µ –Ω–∞ –∫–∞—Ç–µ–≥–æ—Ä–∏—è—Ö"""
        category_examples = defaultdict(list)
        subcategory_examples = defaultdict(list)
        
        for _, row in df.iterrows():
            xname = str(row.get('xname', '')).upper()
            category = str(row.get('category', '')).strip()
            subcategory = str(row.get('subcategory', '')).strip()
            
            if category and category != 'nan':
                category_examples[category].append(xname)
            
            if subcategory and subcategory != 'nan':
                subcategory_examples[subcategory].append(xname)
        
        self.stats['categories_learned'] = len(category_examples)
        
        self.knowledge_base['categories'] = {
            'main_categories': {
                cat: {
                    'count': len(examples),
                    'examples': examples[:5]
                }
                for cat, examples in category_examples.items()
            },
            'subcategories': {
                subcat: {
                    'count': len(examples),
                    'examples': examples[:5]
                }
                for subcat, examples in subcategory_examples.items()
            }
        }
        
        print(f"  –ò–∑—É—á–µ–Ω–æ –∫–∞—Ç–µ–≥–æ—Ä–∏–π: {len(category_examples)}")
        print(f"  –ò–∑—É—á–µ–Ω–æ –ø–æ–¥–∫–∞—Ç–µ–≥–æ—Ä–∏–π: {len(subcategory_examples)}")
    
    def _learn_volumes(self, df: pd.DataFrame):
        """–û–±—É—á–µ–Ω–∏–µ –Ω–∞ –æ–±—ä–µ–º–∞—Ö"""
        volume_categories = defaultdict(list)
        
        for _, row in df.iterrows():
            catlitrag = str(row.get('catlitrag', '')).strip()
            litrag = row.get('litrag', None)
            
            if catlitrag and catlitrag != 'nan':
                if litrag and not pd.isna(litrag):
                    volume_categories[catlitrag].append(float(litrag))
        
        # –í—ã—á–∏—Å–ª—è–µ–º —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É –ø–æ –∫–∞—Ç–µ–≥–æ—Ä–∏—è–º –æ–±—ä–µ–º–æ–≤
        self.knowledge_base['volume_categories'] = {
            cat: {
                'count': len(volumes),
                'min': min(volumes) if volumes else 0,
                'max': max(volumes) if volumes else 0,
                'avg': sum(volumes) / len(volumes) if volumes else 0
            }
            for cat, volumes in volume_categories.items()
        }
        
        print(f"  –ò–∑—É—á–µ–Ω–æ –∫–∞—Ç–µ–≥–æ—Ä–∏–π –æ–±—ä–µ–º–æ–≤: {len(volume_categories)}")
        for cat, info in self.knowledge_base['volume_categories'].items():
            print(f"    {cat}: {info['min']:.2f}–õ - {info['max']:.2f}–õ (—Å—Ä–µ–¥–Ω–µ–µ: {info['avg']:.2f}–õ)")
    
    def _learn_patterns(self, product_df: pd.DataFrame, sku_df: pd.DataFrame):
        """–ê–Ω–∞–ª–∏–∑ –ø–∞—Ç—Ç–µ—Ä–Ω–æ–≤ –≤ –Ω–∞–∑–≤–∞–Ω–∏—è—Ö —Ç–æ–≤–∞—Ä–æ–≤"""
        
        print("  –ê–Ω–∞–ª–∏–∑ –ø–∞—Ç—Ç–µ—Ä–Ω–æ–≤ –≤ –Ω–∞–∑–≤–∞–Ω–∏—è—Ö...")
        
        # –ü–∞—Ç—Ç–µ—Ä–Ω—ã –¥–ª—è –±—Ä–µ–Ω–¥–æ–≤ - –≥–¥–µ –æ–Ω–∏ –æ–±—ã—á–Ω–æ –Ω–∞—Ö–æ–¥—è—Ç—Å—è –≤ –Ω–∞–∑–≤–∞–Ω–∏–∏
        brand_positions = []
        
        # –ò–∑–≤–ª–µ–∫–∞–µ–º —Å—Ç—Ä—É–∫—Ç—É—Ä—É xname
        xname_patterns = {
            'has_parentheses': 0,  # –ï—Å—Ç—å —Å–∫–æ–±–∫–∏ ()
            'has_colon': 0,        # –ï—Å—Ç—å –¥–≤–æ–µ—Ç–æ—á–∏–µ :
            'has_volume': 0,       # –ï—Å—Ç—å –æ–±—ä–µ–º (–õ, –ú–õ)
            'has_packaging': 0,    # –ï—Å—Ç—å —É–ø–∞–∫–æ–≤–∫–∞ (–ü–≠–¢, –°–¢–ï–ö–õ–û)
            'total': 0
        }
        
        for _, row in product_df.iterrows():
            xname = str(row.get('xname', '')).upper()
            brand = str(row.get('brand', '')).strip().upper()
            
            xname_patterns['total'] += 1
            
            if '(' in xname:
                xname_patterns['has_parentheses'] += 1
            if ':' in xname:
                xname_patterns['has_colon'] += 1
            if '–õ' in xname or 'ML' in xname:
                xname_patterns['has_volume'] += 1
            if any(pkg in xname for pkg in ['–ü–≠–¢', 'PET', '–°–¢–ï–ö–õ–û', '–ë–ê–ù–ö–ê', 'CAN']):
                xname_patterns['has_packaging'] += 1
            
            if brand and brand != 'LOCAL' and brand != 'nan' and brand in xname:
                position = xname.index(brand)
                relative_position = position / len(xname) if len(xname) > 0 else 0
                brand_positions.append(relative_position)
        
        # –ü–∞—Ç—Ç–µ—Ä–Ω—ã –¥–ª—è –≤–∫—É—Å–æ–≤
        flavor_keywords = Counter()
        flavor_positions = []
        
        for _, row in sku_df.iterrows():
            xname = str(row.get('xname', '')).upper()
            vkus = str(row.get('vkus', '')).strip().upper()
            
            if vkus and vkus not in ['LOCAL', 'CLASSIC', 'nan']:
                # –ò—â–µ–º –∫–ª—é—á–µ–≤—ã–µ —Å–ª–æ–≤–∞ –≤–æ–∫—Ä—É–≥ –≤–∫—É—Å–∞
                if vkus in xname:
                    idx = xname.index(vkus)
                    position = idx / len(xname) if len(xname) > 0 else 0
                    flavor_positions.append(position)
                    
                    # –ë–µ—Ä–µ–º —Å–ª–æ–≤–∞ –¥–æ –∏ –ø–æ—Å–ª–µ
                    words_before = re.findall(r'\b\w+\b', xname[:idx])[-2:] if idx > 0 else []
                    words_after = re.findall(r'\b\w+\b', xname[idx:])[:2]
                    
                    for word in words_before + words_after:
                        if len(word) > 2:
                            flavor_keywords[word] += 1
        
        # –°–æ—Ö—Ä–∞–Ω—è–µ–º –ø–∞—Ç—Ç–µ—Ä–Ω—ã
        self.knowledge_base['xname_structure'] = {
            'parentheses_ratio': xname_patterns['has_parentheses'] / xname_patterns['total'] if xname_patterns['total'] > 0 else 0,
            'colon_ratio': xname_patterns['has_colon'] / xname_patterns['total'] if xname_patterns['total'] > 0 else 0,
            'volume_ratio': xname_patterns['has_volume'] / xname_patterns['total'] if xname_patterns['total'] > 0 else 0,
            'packaging_ratio': xname_patterns['has_packaging'] / xname_patterns['total'] if xname_patterns['total'] > 0 else 0,
        }
        
        self.knowledge_base['brand_patterns'] = {
            'typical_positions': {
                'beginning': sum(1 for p in brand_positions if p < 0.3) / len(brand_positions) if brand_positions else 0,
                'middle': sum(1 for p in brand_positions if 0.3 <= p < 0.7) / len(brand_positions) if brand_positions else 0,
                'end': sum(1 for p in brand_positions if p >= 0.7) / len(brand_positions) if brand_positions else 0
            }
        }
        
        self.knowledge_base['flavor_patterns'] = {
            'typical_positions': {
                'beginning': sum(1 for p in flavor_positions if p < 0.3) / len(flavor_positions) if flavor_positions else 0,
                'middle': sum(1 for p in flavor_positions if 0.3 <= p < 0.7) / len(flavor_positions) if flavor_positions else 0,
                'end': sum(1 for p in flavor_positions if p >= 0.7) / len(flavor_positions) if flavor_positions else 0
            },
            'common_context_words': [word for word, count in flavor_keywords.most_common(30)]
        }
        
        self.stats['patterns_learned'] = len(flavor_keywords)
        
        print(f"  ‚úì –ò–∑—É—á–µ–Ω–æ –ø–∞—Ç—Ç–µ—Ä–Ω–æ–≤: {self.stats['patterns_learned']}")
        print(f"\n  üìã –°—Ç—Ä—É–∫—Ç—É—Ä–∞ –Ω–∞–∑–≤–∞–Ω–∏–π (xname):")
        print(f"    –°–æ —Å–∫–æ–±–∫–∞–º–∏: {xname_patterns['has_parentheses']:5d} ({self.knowledge_base['xname_structure']['parentheses_ratio']*100:5.1f}%)")
        print(f"    –° –¥–≤–æ–µ—Ç–æ—á–∏–µ–º: {xname_patterns['has_colon']:5d} ({self.knowledge_base['xname_structure']['colon_ratio']*100:5.1f}%)")
        print(f"    –° –æ–±—ä–µ–º–æ–º: {xname_patterns['has_volume']:5d} ({self.knowledge_base['xname_structure']['volume_ratio']*100:5.1f}%)")
        print(f"    –° —É–ø–∞–∫–æ–≤–∫–æ–π: {xname_patterns['has_packaging']:5d} ({self.knowledge_base['xname_structure']['packaging_ratio']*100:5.1f}%)")
        print(f"\n  üìç –ü–æ–∑–∏—Ü–∏—è –±—Ä–µ–Ω–¥–æ–≤ –≤ –Ω–∞–∑–≤–∞–Ω–∏–∏:")
        print(f"    –í –Ω–∞—á–∞–ª–µ: {self.knowledge_base['brand_patterns']['typical_positions']['beginning']*100:.1f}%")
        print(f"    –í —Å–µ—Ä–µ–¥–∏–Ω–µ: {self.knowledge_base['brand_patterns']['typical_positions']['middle']*100:.1f}%")
        print(f"    –í –∫–æ–Ω—Ü–µ: {self.knowledge_base['brand_patterns']['typical_positions']['end']*100:.1f}%")
    
    def _learn_packaging(self, df: pd.DataFrame):
        """–û–±—É—á–µ–Ω–∏–µ –Ω–∞ —Ç–∏–ø–∞—Ö —É–ø–∞–∫–æ–≤–∫–∏"""
        packaging_types = Counter()
        
        for _, row in df.iterrows():
            pack = str(row.get('pack', '')).strip()
            if pack and pack != 'nan':
                packaging_types[pack] += 1
        
        self.knowledge_base['packaging_types'] = {
            pack: count for pack, count in packaging_types.items()
        }
        
        print(f"  –ò–∑—É—á–µ–Ω–æ —Ç–∏–ø–æ–≤ —É–ø–∞–∫–æ–≤–∫–∏: {len(packaging_types)}")
        for pack, count in packaging_types.most_common():
            print(f"    {pack}: {count} —Ç–æ–≤–∞—Ä–æ–≤")
    
    def _save_knowledge_base(self):
        """–°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –±–∞–∑—ã –∑–Ω–∞–Ω–∏–π –≤ JSON"""
        with open(self.knowledge_base_path, 'w', encoding='utf-8') as f:
            json.dump(self.knowledge_base, f, ensure_ascii=False, indent=2)
        
        print(f"  –ë–∞–∑–∞ –∑–Ω–∞–Ω–∏–π —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∞ –≤: {self.knowledge_base_path}")
        
        # –°–æ—Ö—Ä–∞–Ω—è–µ–º —Ç–∞–∫–∂–µ –±–∞–∑—ã –∏–∑ –¥—Ä—É–≥–∏—Ö –∫–æ–º–ø–æ–Ω–µ–Ω—Ç–æ–≤
        self.brand_matcher.save_brands_db()
        print(f"  –ë–∞–∑–∞ –±—Ä–µ–Ω–¥–æ–≤ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∞ –≤: {self.brands_db_path}")
    
    def _print_statistics(self):
        """–í—ã–≤–æ–¥ —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏ –æ–±—É—á–µ–Ω–∏—è"""
        print("\n" + "="*80)
        print("–°–¢–ê–¢–ò–°–¢–ò–ö–ê –û–ë–£–ß–ï–ù–ò–Ø")
        print("="*80)
        print(f"–í—Å–µ–≥–æ –æ–±—Ä–∞–±–æ—Ç–∞–Ω–æ —Ç–æ–≤–∞—Ä–æ–≤: {self.stats['total_products']}")
        print(f"–ò–∑—É—á–µ–Ω–æ –±—Ä–µ–Ω–¥–æ–≤: {self.stats['brands_learned']}")
        print(f"–ò–∑—É—á–µ–Ω–æ –≤–∫—É—Å–æ–≤: {self.stats['flavors_learned']}")
        print(f"–ò–∑—É—á–µ–Ω–æ –∫–∞—Ç–µ–≥–æ—Ä–∏–π: {self.stats['categories_learned']}")
        print(f"–ò–∑—É—á–µ–Ω–æ –ø–∞—Ç—Ç–µ—Ä–Ω–æ–≤: {self.stats['patterns_learned']}")
        print("="*80 + "\n")


class ModelValidator:
    """–í–∞–ª–∏–¥–∞—Ç–æ—Ä –º–æ–¥–µ–ª–∏ - –ø—Ä–æ–≤–µ—Ä–∫–∞ –∫–∞—á–µ—Å—Ç–≤–∞ —Ä–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏—è"""
    
    def __init__(self, learning_engine: LearningEngine):
        self.engine = learning_engine
    
    def validate(self, df: pd.DataFrame, sample_size: int = 1000) -> Dict:
        """–í–∞–ª–∏–¥–∞—Ü–∏—è –º–æ–¥–µ–ª–∏ –Ω–∞ –≤—ã–±–æ—Ä–∫–µ –¥–∞–Ω–Ω—ã—Ö"""
        print("\n" + "="*80)
        print("–í–ê–õ–ò–î–ê–¶–ò–Ø –ú–û–î–ï–õ–ò")
        print("="*80 + "\n")
        
        # –ë–µ—Ä–µ–º —Å–ª—É—á–∞–π–Ω—É—é –≤—ã–±–æ—Ä–∫—É
        sample = df.sample(min(sample_size, len(df)))
        
        results = {
            'total': len(sample),
            'brand_correct': 0,
            'brand_partial': 0,
            'brand_wrong': 0,
            'volume_correct': 0,
            'packaging_correct': 0
        }
        
        for _, row in sample.iterrows():
            xname = str(row.get('xname', ''))
            actual_brand = str(row.get('brand', '')).strip().upper()
            actual_volume = row.get('litrag', None)
            actual_pack = str(row.get('pack', '')).strip().upper()
            
            # –ü–∞—Ä—Å–∏–º –Ω–∞–∑–≤–∞–Ω–∏–µ
            features = self.engine.parser.parse(xname)
            
            # –ü—ã—Ç–∞–µ–º—Å—è –Ω–∞–π—Ç–∏ –±—Ä–µ–Ω–¥
            brand_match = self.engine.brand_matcher.match_brand(
                xname, 
                list(self.engine.brand_matcher.brands_db.get('brands', {}).keys())
            )
            
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º –±—Ä–µ–Ω–¥
            if brand_match and actual_brand != 'LOCAL' and actual_brand != 'nan':
                if brand_match.matched_brand.upper() == actual_brand:
                    results['brand_correct'] += 1
                elif brand_match.confidence >= 75:
                    results['brand_partial'] += 1
                else:
                    results['brand_wrong'] += 1
            
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º –æ–±—ä–µ–º
            if features.volume and actual_volume:
                if abs(features.volume - float(actual_volume)) < 0.01:
                    results['volume_correct'] += 1
            
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º —É–ø–∞–∫–æ–≤–∫—É
            if features.packaging and actual_pack != 'nan':
                if features.packaging == actual_pack:
                    results['packaging_correct'] += 1
        
        # –í—ã—á–∏—Å–ª—è–µ–º —Ç–æ—á–Ω–æ—Å—Ç—å
        total_brands = results['brand_correct'] + results['brand_partial'] + results['brand_wrong']
        
        print(f"–†–µ–∑—É–ª—å—Ç–∞—Ç—ã –≤–∞–ª–∏–¥–∞—Ü–∏–∏ –Ω–∞ {results['total']} —Ç–æ–≤–∞—Ä–∞—Ö:")
        print(f"\n–¢–æ—á–Ω–æ—Å—Ç—å —Ä–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏—è –±—Ä–µ–Ω–¥–æ–≤:")
        if total_brands > 0:
            print(f"  –¢–æ—á–Ω–æ: {results['brand_correct']} ({results['brand_correct']/total_brands*100:.1f}%)")
            print(f"  –ß–∞—Å—Ç–∏—á–Ω–æ: {results['brand_partial']} ({results['brand_partial']/total_brands*100:.1f}%)")
            print(f"  –ù–µ–≤–µ—Ä–Ω–æ: {results['brand_wrong']} ({results['brand_wrong']/total_brands*100:.1f}%)")
        
        print(f"\n–¢–æ—á–Ω–æ—Å—Ç—å —Ä–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏—è –æ–±—ä–µ–º–æ–≤: {results['volume_correct']/results['total']*100:.1f}%")
        print(f"–¢–æ—á–Ω–æ—Å—Ç—å —Ä–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏—è —É–ø–∞–∫–æ–≤–∫–∏: {results['packaging_correct']/results['total']*100:.1f}%")
        print("="*80 + "\n")
        
        return results


if __name__ == "__main__":
    # –û–±—É—á–µ–Ω–∏–µ —Å–∏—Å—Ç–µ–º—ã
    engine = LearningEngine(
        product_file='/workspace/product1.xlsx',
        sku_file='/workspace/sku_vkus.xlsx',
        knowledge_base_path='/workspace/knowledge_base.json',
        brands_db_path='/workspace/brands_db.json'
    )
    
    # –ó–∞–ø—É—Å–∫ –æ–±—É—á–µ–Ω–∏—è
    knowledge_base = engine.learn_from_data()
    
    # –í–∞–ª–∏–¥–∞—Ü–∏—è
    product_df, _ = engine.load_data()
    validator = ModelValidator(engine)
    validation_results = validator.validate(product_df, sample_size=500)
